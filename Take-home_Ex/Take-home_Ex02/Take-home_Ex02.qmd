---
title: "Take-home Exercise 2: Application of Spatial and Spatio-temporal Analysis Methods to Discover the Distribution of Dengue Fever in Tainan City, Taiwan"
author: "Gerald Lim"
date: "`r Sys.Date()`"
format: 
  html: 
    code-fold: true
    code-summary: "Show the code"
    toc-depth: 4
output:
  html_document:
    toc: true
    code_echo: false
execute:
  warning: false
  freeze: false
---

## **DISCLAIMER (Read this before you scroll down):**

1.  **Some parts of this document have hidden codes that are kept PRIVATE for now. They contain confidential codes which I will ONLY be disclosing them on 1 March 2024 (week 9).**

2.  **I will ONLY provide explanations for the exercise right now, and it is subjected to change during the duration of this exercise.**

3.  **It is important to be honest and fair in our work, and respect the privacy of the work of others, so as to uphold academic integrity throughout the duration of this take-home exercise.**

## **Setting the Scene**

Dengue Hemorrhagic Fever (in short dengue fever) is one of the most widespread mosquito-borne diseases in the most tropical and subtropical regions. It is an acute disease caused by dengue virus infection which is transmitted by female Aedes aegypti and Aedes albopictus mosquitoes. In 2015, Taiwan had recorded the most severe dengue fever outbreak with more than 43,000 dengue cases and 228 deaths. Since then, the annual reported dengue fever cases were maintained at the level of not more than 200 cases. However, in 2023, Taiwan recorded 26703 dengue fever cases. Figure below reveals that more than 25,000 cases were reported at Tainan City.

![](https://is415-ay2023-24t2.netlify.app/img/df1.jpg)

## **Objectives**

As a curious geospatial analytics green horn, you are interested to discover:

-   if the distribution of dengue fever outbreak at Tainan City, Taiwan are independent from space and space and time.

-   If the outbreak is indeed spatial and spatio-temporal dependent, then, you would like to detect where are the clusters and outliers, and the emerging hot spot/cold spot areas.

## 1 Install maptools

```{r}
#| eval: false 
install.packages("maptools", repos = "https://packagemanager.posit.co/cran/2023-10-13")
```

Installing the required tools for the analysis (e.g. sf, tidyverse, maptools, etc)

```{r}
pacman::p_load(maptools, sf, raster, spatstat, tmap, tidyverse, arrow, lubridate, dplyr, spNetwork, spacetime, spdep, sfdep)
```

## 2 Data Import, Wrangling and Analysis

This is where we import the data and prepare it before analysis.

Let's use st_read() of sf package to import these two geospatial data sets into R. And we will be using other functions to prepare our data upon importing them. Moreover, we will also perform some simple operation on the datasets to gather some basic analysis.

The 2 data sets are:

-   TAIWAN_VILLAGE_2020, a geospatial data of village boundary of Taiwan. It is in ESRI shapefile format. The data is in Taiwan Geographic Coordinate System. (Source: [Historical map data of the village boundary: TWD97 longitude and latitude](https://data.gov.tw/en/datasets/130549))

-   Dengue_Daily.csv, an aspatial data of reported dengue cases in Taiwan since 1998. (Source: [Dengue Daily Confirmed Cases Since 1998](https://data.cdc.gov.tw/en/dataset/dengue-daily-determined-cases-1998). Below are selected fields that are useful for this study:

    -   發病日: Onset date

    -   最小統計區中心點X: x-coordinate

    -   最小統計區中心點Y: y-coordinate

### 2.1 Taiwan Village Data (taiwan_village_sf)

#### 2.1.1 Import the csv data (TAINAN_VILLAGE.shp)

Firstly, we will import the data for the Taiwan Village Data

```{r}
#| eval: false
taiwan_village_sf <- st_read(dsn = "data/geospatial", layer = "TAINAN_VILLAGE")
```

Let's check the referencing system info of this taiwan_village_sf

```{r}
#| eval: false
st_crs(taiwan_village_sf)
```

#### 2.1.2 Filtering the taiwan_village_sf.

Currently, we have 649 rows of data in taiwan_village_sf.

![](images/clipboard-933829746.png)

Therefore, we have to filter the taiwan_village_sf for village level of D01, D02, D04, D06, D07, D08, D32, and D39 of the Tainan City, Taiwan

```{r}
#| echo: false
#| eval: false
#taiwan_village_sf <- st_transform(taiwan_village_sf, CRS=3414) - not needed
#filter the specific town ID from taiwan_village_sf
filtered_taiwan_village_sf <- taiwan_village_sf %>%
  filter(TOWNID %in% c("D01", "D02", "D04", "D06", "D07", "D08", "D32", "D39"))
```

Now, filtered_taiwan_village_sf will consist of 258 rows of data. This will help to reduce the amount of data that is needed to be processed in the later parts.

![](images/clipboard-1325127262.png)

#### 2.1.3 Saving it to RDS

Since we're happy with the dataset for filtered_taiwan_village_sf, let's save it to a rds so that it would be easier for us to retrieve it in the future

```{r}
#| echo: false
#| eval: false
write_rds(filtered_taiwan_village_sf, "data/rds/filtered_taiwan_village_sf.rds")
```

Import the filtered_taiwan_village_sf rds data

```{r}
#| echo: false
filtered_taiwan_village_sf <- read_rds("data/rds/filtered_taiwan_village_sf.rds")
```

#### 2.1.4 Visualise the dataset by plotting it

Let's visualise how filtered_taiwan_village_sf looks like when we plot it

```{r}
#| echo: false
tmap_mode("plot") 
tm_shape(filtered_taiwan_village_sf) + 
  tm_dots()
```

### 2.2 Dengue Data (dengue_sf)

#### 2.2.1 Import the csv data (Dengue_Daily.csv)

Firstly, we will import the data for the Dengue Data

```{r}
#| eval: false
dengue_sf <- read_csv("data/aspatial/Dengue_Daily.csv")
```

As dengue_sf consists of 106861 rows of data, with 26 types of variables, as shown below. Therefore we need to filter it

![](images/clipboard-342559558.png)

#### 2.2.2 Filtering the dengue_sf

Let's filter dengue_sf for fever cases that are confined to epidemiology week 31-50 of 2023, as well as the selected variables which we will be working with (發病日: Onset date, 居住縣市: County, 居住鄉鎮: Town, 居住村里: Village, 最小統計區中心點X: x-coordinate, 最小統計區中心點Y: y-coordinate)

```{r}
#| echo: false
#| eval: false

# Filter the dataset for fever cases confined to epidemiology week 31-50, 2023
filtered_dengue_sf <- dengue_sf %>%
  filter(發病日 >= "2023-07-31" & 發病日 <= "2023-12-17") %>%
  select(發病日, 居住縣市, 居住鄉鎮, 居住村里, 最小統計區中心點X, 最小統計區中心點Y)
```

In the code chunk above, we filtered the specific data that falls under the weeks that we are interested to look into. Moreover, we also use the "select" line to select the specific variables that we deemed useful for our research.

After filtering dengue_sf, and storing it in filtered_dengue_sf, the amount of data has reduced significantly from 106861 rows of data in dengue_sf, to 25480 rows of data in filtered_dengue_sf (with 3 types of variables).

![](images/clipboard-1392265263.png)

Let's check the data type of each variable before we proceed to performing left-join

```{r}
#| echo: false
#| eval: false
str(filtered_dengue_sf)
```

Let's transform some of our variables and prepare it for the left-join operation in step 2.3

-   Since the X and Y coordinates are in string format, we need to convert it to numeric.
-   This is the same for onset date where we need to convert it to date format

```{r}
#| echo: false
#| eval: false
# Convert the columns to numeric
filtered_dengue_sf$發病日 <- as.Date(filtered_dengue_sf$發病日)
filtered_dengue_sf$最小統計區中心點X <- as.numeric(filtered_dengue_sf$最小統計區中心點X)
filtered_dengue_sf$最小統計區中心點Y <- as.numeric(filtered_dengue_sf$最小統計區中心點Y)
```

Let's create 3 different variables that stores the week number, month and day respectively. This is to facilitate our research and analysis in the later parts of this take-home exercise.

```{r}
#| echo: false
#| eval: false
# Extract week number, month, and day separately
filtered_dengue_sf$epi_week_num <- format(filtered_dengue_sf$發病日, "%U")
filtered_dengue_sf$month <- format(filtered_dengue_sf$發病日, "%m")
filtered_dengue_sf$day <- format(filtered_dengue_sf$發病日, "%d")

# Display the first few rows of the modified dataset
head(filtered_dengue_sf)
```

However, in our dengue dataset, we have noticed that there are rows of data with no village name. As our research is focused mainly on the village level, we will remove the rows with village name = "None". \[SKIP FIRST\]

![](images/clipboard-459349656.png){width="612"}

```{r}
#| echo: false
#| eval: false
# Remove rows with village name = "None"
filtered_dengue_sf <- filtered_dengue_sf %>%
  filter(居住村里 != "None")
```

#### 2.2.3 Basic Analysis of filtered_dengue_sf dataset

Since we have the finalised filtered_dengue_sf, it is important for us to create a new table to store the number of cases, grouped by the **day** and **village**. We will store it in cases_by_day_village dataset.

```{r}
#| echo: false
#| eval: false
# Step 1: Group by day and village, then count the number of cases
cases_by_day_village <- filtered_dengue_sf %>%
  group_by(發病日, 居住村里, 最小統計區中心點X, 最小統計區中心點Y) %>%
  summarise(num_cases = n())

# Step 2: Optionally, you can rename the columns for clarity
names(cases_by_day_village) <- c("Date", "Village", "XCoordinate", "YCoordinate", "Num_Cases")

# Step 3: View the resulting dataframe
head(cases_by_day_village)
```

A snippet of the resulting dataset for **cases_by_day_village** looks like this:

![](images/clipboard-3333388626.png){width="450"}

In addition to the cases_by_day_village dataset, it would be useful for us to create a new table to store the number of cases, grouped by the **week** and **village**. We will store it in **cases_by_week_village** dataset.

```{r}
#| echo: false
#| eval: false
# Step 1: Group by day and village, then count the number of cases
cases_by_week_village <- filtered_dengue_sf %>%
  group_by(epi_week_num, 居住村里, 最小統計區中心點X, 最小統計區中心點Y) %>%
  summarise(num_cases = n())

# Step 2: Optionally, you can rename the columns for clarity
names(cases_by_week_village) <- c("epi_week_num", "Village", "XCoordinate", "YCoordinate", "Num_Cases")

# Step 3: View the resulting dataframe
head(cases_by_week_village)
```

A snippet of the resulting dataset for **cases_by_week_village** looks like this:

![](images/clipboard-2633481134.png){width="537"}

To get the number of cases in througout Tainan city during the whole epidemiology week 31-50, it would be useful for us to create a new table to store the number of cases for each village. We will store it in **cases_by_village** dataset.

```{r}
#| echo: false
#| eval: false
# Step 1: Group by day and village, then count the number of cases
cases_by_village  <- filtered_dengue_sf %>%
  group_by(居住村里, 最小統計區中心點X, 最小統計區中心點Y) %>%
  summarise(num_cases = n())

# Step 2: Optionally, you can rename the columns for clarity
names(cases_by_village) <- c("village", "XCoordinate", "YCoordinate", "Num_Cases")

# Step 3: View the resulting dataframe
head(cases_by_village)
```

A snippet of the resulting dataset for **cases_by_village** looks like this:

![](images/clipboard-483203027.png){width="433"}

To get the number of cases in a week througout Tainan city, it would be useful for us to create a new table to store the number of cases, grouped by the **week** alone. We will store it in **cases_by_week** dataset.

```{r}
#| echo: false
#| eval: false
# Step 1: Group by day and village, then count the number of cases
cases_by_week  <- filtered_dengue_sf %>%
  group_by(epi_week_num) %>%
  summarise(num_cases = n())

# Step 2: Optionally, you can rename the columns for clarity
names(cases_by_week) <- c("epi_week_num", "Num_Cases")

# Step 3: View the resulting dataframe
head(cases_by_week)
```

A snippet of the resulting dataset for **cases_by_week** looks like this:

![](images/clipboard-941645063.png)

Now, we have found valuable analysis from our dataset, let's move on to the next section where we keep them in rds form.

#### 2.2.4 Saving it to RDS

Since we're happy with the dataset for filtered_taiwan_village_sf, and datasets from our analysis in 2.2.3, let's save it to a rds so that it would be easier for us to retrieve it in the future

```{r}
#| echo: false
#| eval: false
write_rds(filtered_dengue_sf, "data/rds/filtered_dengue_sf.rds")
write_rds(cases_by_day_village, "data/rds/cases_by_day_village.rds")
write_rds(cases_by_week_village, "data/rds/cases_by_week_village.rds")
write_rds(cases_by_week, "data/rds/cases_by_week.rds")
write_rds(cases_by_village, "data/rds/cases_by_village.rds")
```

Import the filtered_taiwan_village_sf rds data

```{r}
#| echo: false
filtered_dengue_sf <- read_rds("data/rds/filtered_dengue_sf.rds")
cases_by_day_village <- read_rds("data/rds/cases_by_day_village.rds")
cases_by_week_village <- read_rds("data/rds/cases_by_week_village.rds")
cases_by_week <- read_rds("data/rds/cases_by_week.rds")
cases_by_village <- read_rds("data/rds/cases_by_village.rds")
```

Let's take a look at our Dengue datasets in 2.2 before we move on to 2.3 :)

**filtered_dengue_sf**

-   I have included the 居住縣市 (County), 居住鄉鎮 (Town) and 居住村里 (Village) into the data set for easier future reference.

![](images/clipboard-2567583851.png){width="829"}

### 2.3 Performing Join operation to combine both data sets

Let's perform a join operation to combine the variables in filtered_taiwan_village_sf and filtered_dengue_sf.

Our goal is to perform the join operation to the **cases_by_week_village** and supplement it with the specific geospatial and relevant variable. We will be operating the join operation based on the Village Name of both dataset as we want to retrieve the distinct geospatial infromation from **filtered_taiwan_village_sf** for each dengue cases.

The reason for using cases_by_week_village is because we are focusing on the number of cases in each village on a weekly basis.

#### 2.3.1 Left-Join Operation and Outcome

Before we perform the left-join operation, we can see that the cases_by_village is not a spatial data. As for filtered_taiwan_village_sf, we have already checked the data type of the file is already in spatial data type (TWD97).

```{r}
st_crs(cases_by_week_village)
```

Therefore we have to convert the cases_by_village dataset into a spatial data.

Before we transform it into a spatial data, we have to vet through our data in cases_by_village and case_by_village dataset. There are rows where there are "NA" values for the village name, X and Y coordinates, which could potentially cause issues in the future analysis.

![](images/clipboard-977836271.png)

And we have to clean up the NA values before proceeding to case_by_village into a spatial data.

One option that we could remove the NA values which could potentially create problems in our future analysis, and they wouldn't provide us with accurate analysis. On the other hand, if we were to adopt the other option which is to find the mean / median of the x and y coordinates for the missing values, it would also affect the accuracy of our analysis.

```{r}
#| echo: false
# Convert cases_by_village to sf object
cases_by_week_village <- cases_by_week_village[complete.cases(cases_by_week_village[, c("XCoordinate", "YCoordinate")]), ]
```

Now that we have cleared the NA values, let's transform the case_by_village dataset into a sf

```{r}
#| echo: false
cases_by_week_village_sf <- st_as_sf(cases_by_week_village, coords = c("XCoordinate", "YCoordinate"))
```

```{r}
#| echo: false
st_crs(cases_by_week_village_sf) <- st_crs(4326)
```

```{r}
#| echo: false
cases_by_week_village_sf <- st_transform(cases_by_week_village_sf, crs = st_crs(filtered_taiwan_village_sf))
```

The join dataset would be named taiwan_village_dengue

```{r}
#| echo: false
# Perform left join based on X and Y coordinates
# Perform spatial join
taiwan_village_dengue <- st_join(filtered_taiwan_village_sf, cases_by_week_village_sf, join = st_intersects)
```

After performing the left-join operation, the taiwan_village_dengue dataset seems to have "NA" values. This is due to the fact that the village name (居住村里) value in the filtered_dengue_sf is not found in the list of village name (VILLNAME) in filtered_taiwan_village_sf.

```{r}
#| echo: false
st_crs(taiwan_village_dengue)
```

#### 2.3.2 Saving it to RDS

Since we are happy with our finalised taiwan_village_dengue dataset, let's keep it in our rds for easy reference in the future

```{r}
#| echo: false
#| eval: false 
write_rds(taiwan_village_dengue, "data/rds/taiwan_village_dengue.rds")
```

Import the filtered_taiwan_village_sf rds data

```{r}
#| echo: false
taiwan_village_dengue <- read_rds("data/rds/taiwan_village_dengue.rds")
```

Let's take a look at our taiwan_village_dengue dataset :)

![](images/clipboard-585552616.png)

Let's plot **taiwan_village_dengue** and see how it looks like.

We will create an "**agg_data**" dataset to count the number of cases in each village, and thereafter plot it on tmap, so that we can easily identify which village has a higher number of cases on the map.

```{r}
#| echo: false
# Aggregate cases for each village
agg_data <- taiwan_village_dengue %>%
  group_by(VILLNAME) %>%
  summarise(total_cases = sum(Num_Cases))

# Plot aggregated data
tmap_mode("plot")
tm_shape(agg_data) +
  tm_fill(col = "total_cases",
          style = "quantile",
          palette = "Blues",
          title = "Total Number of Cases") +
  tm_layout(main.title = "Distribution of dengue cases in Tainan City",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45,
            legend.width = 0.35,
            frame = TRUE) +
  tm_borders(alpha = 0.5) +
  tm_scale_bar() +
  tm_grid(alpha = 0.2)
```

Based on the map, we can see that there are some villages that have a significantly higher number of cases. If we look at our **agg_data** dataset, we can see that these are the villages with the highest number of cases.

![](images/clipboard-2228245534.png){width="428"}

## 3 Global spatial autocorrelation analysis by using sfdep methods

### 3.1 Visualizing taiwan_village_dengue

Let's visualize taiwan_village_dengue before we move on to performing global spatial autocorrelation analysis

```{r}
#| echo: false 
equal <- tm_shape(taiwan_village_dengue) +
  tm_fill("Num_Cases",
          n = 5,
          style = "equal") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal interval classification")

quantile <- tm_shape(taiwan_village_dengue) +
  tm_fill("Num_Cases",
          n = 5,
          style = "quantile") +
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "Equal quantile classification")

tmap_arrange(equal, 
             quantile, 
             asp=1, 
             ncol=2)
```

### 3.2 Global Measures of Spatial Autocorrelation

We will be performing Global Measures of Spatial Autocorrelation in this section.

#### 3.2.1 Computing Contiguity Spatial Weights

Before we can perform the global spatial autocorrelation analysis, we need to construct the spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units.

The code calculates a spatial weights matrix using the queen contiguity criterion for the villages in Taiwan represented by polygons in the taiwan_village_dengue dataset, and then provides a summary of this matrix.

```{r}
#| echo: false
wm_q <- poly2nb(taiwan_village_dengue, 
                queen=TRUE)
summary(wm_q)
```

The summary report above shows that there are 13711area units in Tainan City. The observations are:

-   There are 129 **most connected area unit** which has 1056 neighbors

-   There are 4 **least connected area units** with only 15 neighbors

#### 3.2.2 Row-standardised weights matrix

Let's assign weights to each neighboring polygon before we move on to performing our Maron's I test.

```{r}
#| echo: false
rswm_q <- nb2listw(wm_q, 
                   style="W", 
                   zero.policy = TRUE)
rswm_q
```

### 3.3 Global Measures of Spatial Autocorrelation: Moran’s I

#### 3.3.1 Moran's I Test

We will be using Moran's I statistics to test our taiwan_village_dengue dataset.

```{r}
#| echo: false
moran.test(taiwan_village_dengue$Num_Cases, 
           listw=rswm_q, 
           zero.policy = TRUE, 
           na.action=na.omit)
```

Based on the output, the Moran I statistic standard deviate measures the degree of spatial autocorrelation in the variable, Num_cases, in the taiwan_viilage_dengue dataset. In this case, it is 47.203, which indicates a high level of spatial autocorrelation.

In addition, the p-value is very low, at less than 2.2e-16, which indicates that the the spatial correlation is statistically significant. This rejects the null hypothesis that there is no spatial autocorrelation in the data.

Based on the above explanation, it suggests that the areas with high number of dengue cases tend to be clustered together geographically.

#### 3.3.2 Monte Carlo Moran's I

Let's perform simulation on our Moran's I test

```{r}
#| echo: false
set.seed(1234)
bperm= moran.mc(taiwan_village_dengue$Num_Cases, 
                listw=rswm_q, 
                nsim=999, 
                zero.policy = TRUE, 
                na.action=na.omit)
bperm
```

The result indicates that the spatial autocorrelation is statistically significant with the p-value of 0.001.

#### 3.3.3 Visualising Monte Carlo Moran's I

Let's display our findings in a histogram so that we can visualise it better

Firstly, we can get a statistical summary of the Monte Carlo Moran's I output

```{r}
#| echo: false
summary(bperm$res[1:999])
```

Now, we can plot the histogram

```{r}
hist(bperm$res, 
     freq=TRUE, 
     breaks=150, 
     xlab="Simulated Moran's I",
     xlim=c(-0.002, 0.002))
abline(v=0, 
       col="red") 
```

### 3.4 Global Measures of Spatial Autocorrelation: Geary's C

Since we have performed the Moran's I test before this step, we have seen the spatial clustering and dispersion in our dataset, particularly the number of dengue cases in each village.

#### 3.4.1 Geary's C Test

Geary's C test compares the average squared differences in attribute values between neighboring locations to the overall variance in attribute values across all locations.

Now, we will perform Geary's C test to dive into the differences in attribute values between the neighboring observations.

```{r}
geary.test(taiwan_village_dengue$Num_Cases, listw=rswm_q)
```

As we can observe from the result, the Geary's C statistic, at 9.809458e-01 or 0.9809458 being below 1.000, indicates that there are clustering in the spatial pattern.

addtion, the p-value is very small, at 7.772e-05, which indicates a strong rejection to the null hypothesis of no spatial autocorrelation. This means that there is a significant spatial autocorrelation in the distribution of Number of Dengue cases across the villages.

Therefore, a low variance, of 2.537989e-05, indicates that the Geary' C statistic is relatively stable. The observations of the output also indicates that the Number of Dengue cases across the villages, are more similar to their neighbors.

#### 3.4.2 Monte Carlo Geary's C Test

Let's perform simulation on our Geary's C Test

```{r}
set.seed(1234)
bperm1=geary.mc(taiwan_village_dengue$Num_Cases, 
               listw=rswm_q, 
               nsim=999)
bperm1
```

## 4 Local spatial autocorrelation analysis by using sfdep methods

## 5 Analyising emerging hotspot analysis by using sfdep methods
